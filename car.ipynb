{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The imported csv looks like \n",
      "\n",
      "+---+----+---+---+---+-------------+--------------------+---+---+-------+----+\n",
      "|_c0| _c1|_c2|_c3|_c4|          _c5|                 _c6|_c7|_c8|    _c9|_c10|\n",
      "+---+----+---+---+---+-------------+--------------------+---+---+-------+----+\n",
      "|  1|  12|  8|307|130|chevrolet    |chevrolet chevell...| 70| 18|USA    |3504|\n",
      "|  2|11.5|  8|350|165|buick        |buick skylark 320...| 70| 15|USA    |3693|\n",
      "|  3|  11|  8|318|150|plymouth     |plymouth satellit...| 70| 18|USA    |3436|\n",
      "|  4|  12|  8|304|150|amc          |amc rebel sst    ...| 70| 16|USA    |3433|\n",
      "|  5|10.5|  8|302|140|ford         |ford torino      ...| 70| 17|USA    |3449|\n",
      "|  6|  10|  8|429|198|ford         |ford galaxie 500 ...| 70| 15|USA    |4341|\n",
      "|  7|   9|  8|454|220|chevrolet    |chevrolet impala ...| 70| 14|USA    |4354|\n",
      "|  8| 8.5|  8|440|215|plymouth     |plymouth fury iii...| 70| 14|USA    |4312|\n",
      "|  9|  10|  8|455|225|pontiac      |pontiac catalina ...| 70| 14|USA    |4425|\n",
      "| 10| 8.5|  8|390|190|amc          |amc ambassador dp...| 70| 15|USA    |3850|\n",
      "| 11|17.5|  4|133|115|citroen      |citroen ds-21 pal...| 70| 14|France |3090|\n",
      "| 12|11.5|  8|350|165|chevrolet    |chevrolet chevell...| 70| 16|USA    |4142|\n",
      "| 13|  11|  8|351|153|ford         |ford torino (sw) ...| 70| 17|USA    |4034|\n",
      "| 14|10.5|  8|383|175|plymouth     |plymouth satellit...| 70| 19|USA    |4166|\n",
      "| 15|  11|  8|360|175|amc          |amc rebel sst (sw...| 70| 20|USA    |3850|\n",
      "| 16|  10|  8|383|170|dodge        |dodge challenger ...| 70| 15|USA    |3563|\n",
      "| 17|   8|  8|340|160|plymouth     |plymouth 'cuda 34...| 70| 14|USA    |3609|\n",
      "| 18|   8|  8|302|140|ford         |ford mustang boss...| 70| 16|USA    |3353|\n",
      "| 19| 9.5|  8|400|150|chevrolet    |chevrolet monte c...| 70| 15|USA    |3761|\n",
      "| 20|  10|  8|455|225|buick        |buick estate wago...| 70| 14|USA    |3086|\n",
      "+---+----+---+---+---+-------------+--------------------+---+---+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "sc = pyspark.SparkContext.getOrCreate()\n",
    "sql = SQLContext(sc)\n",
    "carDf = (sql.read\n",
    "         .format(\"com.databricks.spark.csv\")\n",
    "         .option(\"header\", \"false\")\n",
    "         .load(\"Small_Car_Data.csv\"))\n",
    "print('The imported csv looks like \\n')\n",
    "carDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      "\n",
      "Dataframe after dropping the serial number column \n",
      "\n",
      "+----+---+---+---+-------------+--------------------+---+---+-------+----+\n",
      "| _c1|_c2|_c3|_c4|          _c5|                 _c6|_c7|_c8|    _c9|_c10|\n",
      "+----+---+---+---+-------------+--------------------+---+---+-------+----+\n",
      "|  12|  8|307|130|chevrolet    |chevrolet chevell...| 70| 18|USA    |3504|\n",
      "|11.5|  8|350|165|buick        |buick skylark 320...| 70| 15|USA    |3693|\n",
      "|  11|  8|318|150|plymouth     |plymouth satellit...| 70| 18|USA    |3436|\n",
      "|  12|  8|304|150|amc          |amc rebel sst    ...| 70| 16|USA    |3433|\n",
      "|10.5|  8|302|140|ford         |ford torino      ...| 70| 17|USA    |3449|\n",
      "|  10|  8|429|198|ford         |ford galaxie 500 ...| 70| 15|USA    |4341|\n",
      "|   9|  8|454|220|chevrolet    |chevrolet impala ...| 70| 14|USA    |4354|\n",
      "| 8.5|  8|440|215|plymouth     |plymouth fury iii...| 70| 14|USA    |4312|\n",
      "|  10|  8|455|225|pontiac      |pontiac catalina ...| 70| 14|USA    |4425|\n",
      "| 8.5|  8|390|190|amc          |amc ambassador dp...| 70| 15|USA    |3850|\n",
      "|17.5|  4|133|115|citroen      |citroen ds-21 pal...| 70| 14|France |3090|\n",
      "|11.5|  8|350|165|chevrolet    |chevrolet chevell...| 70| 16|USA    |4142|\n",
      "|  11|  8|351|153|ford         |ford torino (sw) ...| 70| 17|USA    |4034|\n",
      "|10.5|  8|383|175|plymouth     |plymouth satellit...| 70| 19|USA    |4166|\n",
      "|  11|  8|360|175|amc          |amc rebel sst (sw...| 70| 20|USA    |3850|\n",
      "|  10|  8|383|170|dodge        |dodge challenger ...| 70| 15|USA    |3563|\n",
      "|   8|  8|340|160|plymouth     |plymouth 'cuda 34...| 70| 14|USA    |3609|\n",
      "|   8|  8|302|140|ford         |ford mustang boss...| 70| 16|USA    |3353|\n",
      "| 9.5|  8|400|150|chevrolet    |chevrolet monte c...| 70| 15|USA    |3761|\n",
      "|  10|  8|455|225|buick        |buick estate wago...| 70| 14|USA    |3086|\n",
      "+----+---+---+---+-------------+--------------------+---+---+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#carDf.cache()\n",
    "carDf.printSchema()\n",
    "\n",
    "carDf = carDf.drop('_c0')\n",
    "print('Dataframe after dropping the serial number column \\n')\n",
    "carDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe after dropping the serial number column \n",
      "\n",
      "+----+---+---+---+-------------+---+---+-------+----+\n",
      "| _c1|_c2|_c3|_c4|          _c5|_c7|_c8|    _c9|_c10|\n",
      "+----+---+---+---+-------------+---+---+-------+----+\n",
      "|  12|  8|307|130|chevrolet    | 70| 18|USA    |3504|\n",
      "|11.5|  8|350|165|buick        | 70| 15|USA    |3693|\n",
      "|  11|  8|318|150|plymouth     | 70| 18|USA    |3436|\n",
      "|  12|  8|304|150|amc          | 70| 16|USA    |3433|\n",
      "|10.5|  8|302|140|ford         | 70| 17|USA    |3449|\n",
      "|  10|  8|429|198|ford         | 70| 15|USA    |4341|\n",
      "|   9|  8|454|220|chevrolet    | 70| 14|USA    |4354|\n",
      "| 8.5|  8|440|215|plymouth     | 70| 14|USA    |4312|\n",
      "|  10|  8|455|225|pontiac      | 70| 14|USA    |4425|\n",
      "| 8.5|  8|390|190|amc          | 70| 15|USA    |3850|\n",
      "|17.5|  4|133|115|citroen      | 70| 14|France |3090|\n",
      "|11.5|  8|350|165|chevrolet    | 70| 16|USA    |4142|\n",
      "|  11|  8|351|153|ford         | 70| 17|USA    |4034|\n",
      "|10.5|  8|383|175|plymouth     | 70| 19|USA    |4166|\n",
      "|  11|  8|360|175|amc          | 70| 20|USA    |3850|\n",
      "|  10|  8|383|170|dodge        | 70| 15|USA    |3563|\n",
      "|   8|  8|340|160|plymouth     | 70| 14|USA    |3609|\n",
      "|   8|  8|302|140|ford         | 70| 16|USA    |3353|\n",
      "| 9.5|  8|400|150|chevrolet    | 70| 15|USA    |3761|\n",
      "|  10|  8|455|225|buick        | 70| 14|USA    |3086|\n",
      "+----+---+---+---+-------------+---+---+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "carDf = carDf.drop('_c6')\n",
    "print('Dataframe after dropping the serial number column \\n')\n",
    "carDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c1: integer (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      " |-- _c3: integer (nullable = true)\n",
      " |-- _c4: integer (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c7: integer (nullable = true)\n",
      " |-- _c8: integer (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: integer (nullable = true)\n",
      "\n",
      "+---+---+---+---+---+---+---+---+----+\n",
      "|_c1|_c2|_c3|_c4|_c5|_c7|_c8|_c9|_c10|\n",
      "+---+---+---+---+---+---+---+---+----+\n",
      "|  0|  0|  0|  0|  0|  0|  0|  0|   0|\n",
      "+---+---+---+---+---+---+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "carDf = carDf.withColumn(\"_c1\", carDf[\"_c1\"].cast(IntegerType()))\n",
    "carDf = carDf.withColumn(\"_c2\", carDf[\"_c2\"].cast(IntegerType()))\n",
    "carDf = carDf.withColumn(\"_c3\", carDf[\"_c3\"].cast(IntegerType()))\n",
    "carDf = carDf.withColumn(\"_c4\", carDf[\"_c4\"].cast(IntegerType()))\n",
    "carDf = carDf.withColumn(\"_c7\", carDf[\"_c7\"].cast(IntegerType()))\n",
    "carDf = carDf.withColumn(\"_c8\", carDf[\"_c8\"].cast(IntegerType()))\n",
    "carDf = carDf.withColumn(\"_c10\", carDf[\"_c10\"].cast(IntegerType()))\n",
    "#carDf.cache()\n",
    "carDf.printSchema()\n",
    "\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "carDf.select([count(when(isnan(c), c)).alias(c) for c in carDf.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-------------+---+---+-------+----+-----------+-----------+-------------------+-------------------+--------------------+\n",
      "|_c1|_c2|_c3|_c4|          _c5|_c7|_c8|    _c9|_c10|_c5_indexed|_c9_indexed|_c5_indexed_encoded|_c9_indexed_encoded|            features|\n",
      "+---+---+---+---+-------------+---+---+-------+----+-----------+-----------+-------------------+-------------------+--------------------+\n",
      "| 12|  8|307|130|chevrolet    | 70| 18|USA    |3504|        1.0|        0.0|     (27,[1],[1.0])|      (5,[0],[1.0])|(36,[1,27,32,33,3...|\n",
      "| 11|  8|350|165|buick        | 70| 15|USA    |3693|       10.0|        0.0|    (27,[10],[1.0])|      (5,[0],[1.0])|(36,[10,27,32,33,...|\n",
      "| 11|  8|318|150|plymouth     | 70| 18|USA    |3436|        4.0|        0.0|     (27,[4],[1.0])|      (5,[0],[1.0])|(36,[4,27,32,33,3...|\n",
      "| 12|  8|304|150|amc          | 70| 16|USA    |3433|        2.0|        0.0|     (27,[2],[1.0])|      (5,[0],[1.0])|(36,[2,27,32,33,3...|\n",
      "| 10|  8|302|140|ford         | 70| 17|USA    |3449|        0.0|        0.0|     (27,[0],[1.0])|      (5,[0],[1.0])|(36,[0,27,32,33,3...|\n",
      "+---+---+---+---+-------------+---+---+-------+----+-----------+-----------+-------------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline \n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "#encoding for categorical variables \n",
    "category_variables = ['_c5', '_c9']\n",
    "continuos_variables = ['_c2','_c3','_c7','_c10']\n",
    "\n",
    "indexer = [ StringIndexer(inputCol=c, outputCol=c+\"_indexed\") for c in category_variables ]\n",
    "\n",
    "encoder = [ OneHotEncoder(inputCol=i.getOutputCol(), outputCol=i.getOutputCol()+\"_encoded\")\n",
    "           for i in indexer ]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[e.getOutputCol() for e in encoder] +continuos_variables, \n",
    "                            outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages= indexer + encoder + [assembler])\n",
    "\n",
    "model = pipeline.fit(carDf)\n",
    "\n",
    "data = model.transform(carDf)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-------------+---+---+-------+----+-----------+-----------+-------------------+-------------------+--------------------+\n",
      "|_c1|_c2|_c3|_c4|          _c5|_c7|_c8|    _c9|_c10|_c5_indexed|_c9_indexed|_c5_indexed_encoded|_c9_indexed_encoded|            features|\n",
      "+---+---+---+---+-------------+---+---+-------+----+-----------+-----------+-------------------+-------------------+--------------------+\n",
      "| 12|  8|307|130|chevrolet    | 70| 18|USA    |3504|        1.0|        0.0|     (27,[1],[1.0])|      (5,[0],[1.0])|(36,[1,27,32,33,3...|\n",
      "| 11|  8|350|165|buick        | 70| 15|USA    |3693|       10.0|        0.0|    (27,[10],[1.0])|      (5,[0],[1.0])|(36,[10,27,32,33,...|\n",
      "| 11|  8|318|150|plymouth     | 70| 18|USA    |3436|        4.0|        0.0|     (27,[4],[1.0])|      (5,[0],[1.0])|(36,[4,27,32,33,3...|\n",
      "| 12|  8|304|150|amc          | 70| 16|USA    |3433|        2.0|        0.0|     (27,[2],[1.0])|      (5,[0],[1.0])|(36,[2,27,32,33,3...|\n",
      "| 10|  8|302|140|ford         | 70| 17|USA    |3449|        0.0|        0.0|     (27,[0],[1.0])|      (5,[0],[1.0])|(36,[0,27,32,33,3...|\n",
      "+---+---+---+---+-------------+---+---+-------+----+-----------+-----------+-------------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(carDf)\n",
    "\n",
    "data = model.transform(carDf)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared value on training data is 0.914209\n",
      "R Squared value on test data is 0.808493\n"
     ]
    }
   ],
   "source": [
    "final_dataset = data.select('features','_c4')\n",
    "\n",
    "#splitting the dataset for train and test \n",
    "\n",
    "split = final_dataset.randomSplit([0.9,0.1])\n",
    "train = split[0]\n",
    "test = split[1]\n",
    "\n",
    "#LR model for horsepower \n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "model1 = LinearRegression(featuresCol= 'features', labelCol='_c4')\n",
    "model1 = model1.fit(train)\n",
    "print(\"R Squared value on training data is %g\" % model1.summary.r2)\n",
    "\n",
    "#prediction on test \n",
    "model1_pred = model1.transform(test)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "model1_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"_c4\", metricName=\"r2\")\n",
    "print(\"R Squared value on test data is %g\" % model1_eval.evaluate(model1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared value on training data is 0.913516\n",
      "R Squared value on test data is 0.678084\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_dataset = data.select('features','_c8')\n",
    "\n",
    "#splitting the dataset for train and test \n",
    "\n",
    "split = final_dataset.randomSplit([0.9,0.1])\n",
    "train = split[0]\n",
    "test = split[1]\n",
    "\n",
    "#LR model for horsepower \n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "model2 = LinearRegression(featuresCol= 'features', labelCol='_c8')\n",
    "model2 = model2.fit(train)\n",
    "print(\"R Squared value on training data is %g\" % model2.summary.r2)\n",
    "\n",
    "#prediction on test \n",
    "model2_pred = model2.transform(test)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "model2_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"_c8\", metricName=\"r2\")\n",
    "print(\"R Squared value on test data is %g\" % model2_eval.evaluate(model2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared value on training data is 0.918954\n",
      "R Squared value on test data is 0.594373\n"
     ]
    }
   ],
   "source": [
    "final_dataset = data.select('features','_c4')\n",
    "\n",
    "#splitting the dataset for train and test \n",
    "\n",
    "split = final_dataset.randomSplit([0.9,0.1])\n",
    "train = split[0]\n",
    "test = split[1]\n",
    "\n",
    "#LR model for horsepower \n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "model1 = LinearRegression(featuresCol= 'features', labelCol='_c4')\n",
    "model1 = model1.fit(train)\n",
    "print(\"R Squared value on training data is %g\" % model1.summary.r2)\n",
    "#prediction on test \n",
    "model1_pred = model1.transform(test)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "model1_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"_c4\", metricName=\"r2\")\n",
    "print(\"R Squared value on test data is %g\" % model1_eval.evaluate(model1_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared value on test data is 0.594373\n"
     ]
    }
   ],
   "source": [
    "#prediction on test \n",
    "model1_pred = model1.transform(test)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "model1_eval = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"_c4\", metricName=\"r2\")\n",
    "print(\"R Squared value on test data is %g\" % model1_eval.evaluate(model1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared value on test data is 0.872442\n"
     ]
    }
   ],
   "source": [
    "final_dataset = data.select('features','_c8')\n",
    "\n",
    "#splitting the dataset for train and test \n",
    "\n",
    "split = final_dataset.randomSplit([0.9,0.1])\n",
    "train = split[0]\n",
    "test = split[1]\n",
    "\n",
    "#building the decision tree \n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "dt2 = DecisionTreeRegressor(featuresCol='features', labelCol='_c8')\n",
    "dt2_model1 = dt2.fit(train)\n",
    "\n",
    "#predictions\n",
    "dt2_pred = dt2_model1.transform(test)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "dt2_eval = RegressionEvaluator(predictionCol=\"prediction\",labelCol=\"_c8\",metricName=\"r2\")\n",
    "print(\"R Squared value on test data is %g\" % dt2_eval.evaluate(dt2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
